# TEMPORARILY DISABLED FOR QUOTA COMPLIANCE
# This deployment has been temporarily disabled to meet GCP quota requirements
# Original content below (commented out):
#
# # Comprehensive Monitoring Infrastructure for AIA Platform
# # Prometheus, Grafana, AlertManager, and custom metrics
# 
# apiVersion: v1
# kind: Namespace
# metadata:
#   name: monitoring
#   labels:
#     name: monitoring
# 
# ---
# # Prometheus ConfigMap
# apiVersion: v1
# kind: ConfigMap
# metadata:
#   name: prometheus-config
#   namespace: monitoring
# data:
#   prometheus.yml: |
#     global:
#       scrape_interval: 15s
#       evaluation_interval: 15s
# 
#     rule_files:
#     - "aia-rules.yml"
# 
#     scrape_configs:
#     - job_name: 'aia-backend'
#       static_configs:
#       - targets: ['aia-backend-service.aia-production.svc.cluster.local:8000']
# 
#     - job_name: 'aia-frontend'
#       static_configs:
#       - targets: ['aia-frontend-service.aia-production.svc.cluster.local:80']
# 
#     - job_name: 'aia-ml-processor'
#       static_configs:
#       - targets: ['aia-ml-processor-service.aia-production.svc.cluster.local:8001']
# 
#     - job_name: 'aia-payment-processor'
#       static_configs:
#       - targets: ['aia-payment-processor-service.aia-production.svc.cluster.local:8002']
# 
#     - job_name: 'aia-enterprise-partners'
#       static_configs:
#       - targets: ['aia-enterprise-partners-service.aia-production.svc.cluster.local:8003']
# 
#     - job_name: 'aia-security-service'
#       static_configs:
#       - targets: ['aia-security-service.aia-production.svc.cluster.local:8004']
# 
#     - job_name: 'aia-subscription-manager'
#       static_configs:
#       - targets: ['aia-subscription-manager-service.aia-production.svc.cluster.local:8005']
# 
#     - job_name: 'kubernetes-apiservers'
#       kubernetes_sd_configs:
#       - role: endpoints
#       scheme: https
#       tls_config:
#         ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
#       bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
#       relabel_configs:
#       - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
#         action: keep
#         regex: default;kubernetes;https
# 
#     - job_name: 'kubernetes-nodes'
#       kubernetes_sd_configs:
#       - role: node
#       scheme: https
#       tls_config:
#         ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
#       bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
#       relabel_configs:
#       - action: labelmap
#         regex: __meta_kubernetes_node_label_(.+)
#       - target_label: __address__
#         replacement: kubernetes.default.svc:443
#       - source_labels: [__meta_kubernetes_node_name]
#         regex: (.+)
#         target_label: __metrics_path__
#         replacement: /api/v1/nodes/${1}/proxy/metrics
# 
#     alerting:
#       alertmanagers:
#       - static_configs:
#         - targets:
#           - alertmanager:9093
# 
#   aia-rules.yml: |
#     groups:
#     - name: aia-alerts
#       rules:
#       - alert: AIA-Backend-Down
#         expr: up{job="aia-backend"} == 0
#         for: 1m
#         labels:
#           severity: critical
#           service: backend
#         annotations:
#           summary: "AIA Backend is down"
#           description: "AIA Backend has been down for more than 1 minute"
# 
#       - alert: AIA-High-Response-Time
#         expr: http_request_duration_seconds{quantile="0.95"} > 2
#         for: 5m
#         labels:
#           severity: warning
#           service: "{{ $labels.service }}"
#         annotations:
#           summary: "High response time detected"
#           description: "95th percentile response time is above 2 seconds for {{ $labels.service }}"
# 
#       - alert: AIA-High-Error-Rate
#         expr: (rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m])) > 0.05
#         for: 2m
#         labels:
#           severity: critical
#           service: "{{ $labels.service }}"
#         annotations:
#           summary: "High error rate detected"
#           description: "Error rate is above 5% for {{ $labels.service }}"
# 
#       - alert: AIA-Database-Connection-Issues
#         expr: postgres_up == 0
#         for: 1m
#         labels:
#           severity: critical
#           service: database
#         annotations:
#           summary: "Database connection issues"
#           description: "Unable to connect to PostgreSQL database"
# 
#       - alert: AIA-Redis-Connection-Issues
#         expr: redis_up == 0
#         for: 1m
#         labels:
#           severity: critical
#           service: redis
#         annotations:
#           summary: "Redis connection issues"
#           description: "Unable to connect to Redis instance"
# 
# ---
# # Prometheus Deployment
# apiVersion: apps/v1
# kind: Deployment
# metadata:
#   name: prometheus-server
#   namespace: monitoring
# spec:
#   replicas: 1
#   selector:
#     matchLabels:
#       app: prometheus-server
#   template:
#     metadata:
#       labels:
#         app: prometheus-server
#     spec:
#       serviceAccountName: prometheus-server
#       containers:
#       - name: prometheus
#         image: prom/prometheus:latest
#         args:
#         - --config.file=/etc/prometheus/prometheus.yml
#         - --storage.tsdb.path=/prometheus/
#         - --web.console.libraries=/etc/prometheus/console_libraries
#         - --web.console.templates=/etc/prometheus/consoles
#         - --storage.tsdb.retention.time=200h
#         - --web.enable-lifecycle
#         ports:
#         - containerPort: 9090
#         resources:
#           requests:
#             cpu: "100m"
#             memory: "128Mi"
#           limits:
#             cpu: "100m"
#             memory: "128Mi"
#         volumeMounts:
#         - name: prometheus-config-volume
#           mountPath: /etc/prometheus/
#         - name: prometheus-storage-volume
#           mountPath: /prometheus/
#       volumes:
#       - name: prometheus-config-volume
#         configMap:
#           defaultMode: 420
#           name: prometheus-config
#       - name: prometheus-storage-volume
#         persistentVolumeClaim:
#           claimName: prometheus-storage
# 
# ---
# # Prometheus PVC
# apiVersion: v1
# kind: PersistentVolumeClaim
# metadata:
#   name: prometheus-storage
#   namespace: monitoring
# spec:
#   accessModes:
#   - ReadWriteOnce
#   resources:
#     requests:
#       storage: 50Gi
#   storageClassName: standard-rwo
# 
# ---
# # Prometheus Service
# apiVersion: v1
# kind: Service
# metadata:
#   name: prometheus-server
#   namespace: monitoring
# spec:
#   selector:
#     app: prometheus-server
#   ports:
#   - port: 80
#     targetPort: 9090
#   type: ClusterIP
# 
# ---
# # Prometheus ServiceAccount and RBAC
# apiVersion: v1
# kind: ServiceAccount
# metadata:
#   name: prometheus-server
#   namespace: monitoring
# 
# ---
# apiVersion: rbac.authorization.k8s.io/v1
# kind: ClusterRole
# metadata:
#   name: prometheus-server
# rules:
# - apiGroups: [""]
#   resources:
#   - nodes
#   - nodes/proxy
#   - services
#   - endpoints
#   - pods
#   verbs: ["get", "list", "watch"]
# - apiGroups:
#   - extensions
#   resources:
#   - ingresses
#   verbs: ["get", "list", "watch"]
# 
# ---
# apiVersion: rbac.authorization.k8s.io/v1
# kind: ClusterRoleBinding
# metadata:
#   name: prometheus-server
# roleRef:
#   apiGroup: rbac.authorization.k8s.io
#   kind: ClusterRole
#   name: prometheus-server
# subjects:
# - kind: ServiceAccount
#   name: prometheus-server
#   namespace: monitoring
# 
# ---
# # Grafana ConfigMap
# apiVersion: v1
# kind: ConfigMap
# metadata:
#   name: grafana-datasources
#   namespace: monitoring
# data:
#   prometheus.yaml: |
#     apiVersion: 1
#     datasources:
#     - name: Prometheus
#       type: prometheus
#       url: http://prometheus-server.monitoring.svc.cluster.local:80
#       access: proxy
#       isDefault: true
# 
# ---
# # Grafana Deployment
# apiVersion: apps/v1
# kind: Deployment
# metadata:
#   name: grafana
#   namespace: monitoring
# spec:
#   replicas: 1
#   selector:
#     matchLabels:
#       app: grafana
#   template:
#     metadata:
#       labels:
#         app: grafana
#     spec:
#       containers:
#       - name: grafana
#         image: grafana/grafana:latest
#         ports:
#         - containerPort: 3000
#         env:
#         - name: GF_SECURITY_ADMIN_PASSWORD
#           value: "aia-admin-2024"
#         - name: GF_INSTALL_PLUGINS
#           value: "grafana-piechart-panel,grafana-worldmap-panel"
#         resources:
#           requests:
#             cpu: "100m"
#             memory: "128Mi"
#           limits:
#             cpu: "100m"
#             memory: "128Mi"
#         volumeMounts:
#         - name: grafana-storage
#           mountPath: /var/lib/grafana
#         - name: grafana-datasources
#           mountPath: /etc/grafana/provisioning/datasources
#       volumes:
#       - name: grafana-storage
#         persistentVolumeClaim:
#           claimName: grafana-storage
#       - name: grafana-datasources
#         configMap:
#           defaultMode: 420
#           name: grafana-datasources
# 
# ---
# # Grafana PVC
# apiVersion: v1
# kind: PersistentVolumeClaim
# metadata:
#   name: grafana-storage
#   namespace: monitoring
# spec:
#   accessModes:
#   - ReadWriteOnce
#   resources:
#     requests:
#       storage: 10Gi
#   storageClassName: standard-rwo
# 
# ---
# # Grafana Service
# apiVersion: v1
# kind: Service
# metadata:
#   name: grafana
#   namespace: monitoring
# spec:
#   selector:
#     app: grafana
#   ports:
#   - port: 80
#     targetPort: 3000
#   type: NodePort
# 
# ---
# # AlertManager ConfigMap
# apiVersion: v1
# kind: ConfigMap
# metadata:
#   name: alertmanager-config
#   namespace: monitoring
# data:
#   config.yml: |
#     global:
#       smtp_smarthost: 'smtp.gmail.com:587'
#       smtp_from: 'aia-alerts@013a.tech'
# 
#     route:
#       group_by: ['alertname']
#       group_wait: 10s
#       group_interval: 10s
#       repeat_interval: 1h
#       receiver: 'web.hook'
# 
#     receivers:
#     - name: 'web.hook'
#       email_configs:
#       - to: 'admin@013a.tech'
#         subject: 'AIA Alert: {{ .GroupLabels.alertname }}'
#         body: |
#           Alert: {{ .GroupLabels.alertname }}
# 
#           Summary: {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}
# 
#           Description: {{ range .Alerts }}{{ .Annotations.description }}{{ end }}
# 
#           Time: {{ range .Alerts }}{{ .StartsAt }}{{ end }}
# 
# ---
# # AlertManager Deployment
# apiVersion: apps/v1
# kind: Deployment
# metadata:
#   name: alertmanager
#   namespace: monitoring
# spec:
#   replicas: 1
#   selector:
#     matchLabels:
#       app: alertmanager
#   template:
#     metadata:
#       labels:
#         app: alertmanager
#     spec:
#       containers:
#       - name: alertmanager
#         image: prom/alertmanager:latest
#         args:
#         - --config.file=/etc/alertmanager/config.yml
#         - --storage.path=/alertmanager
#         ports:
#         - containerPort: 9093
#         resources:
#           requests:
#             cpu: "100m"
#             memory: "128Mi"
#           limits:
#             cpu: "100m"
#             memory: "128Mi"
#         volumeMounts:
#         - name: alertmanager-config-volume
#           mountPath: /etc/alertmanager
#       volumes:
#       - name: alertmanager-config-volume
#         configMap:
#           defaultMode: 420
#           name: alertmanager-config
# 
# ---
# # AlertManager Service
# apiVersion: v1
# kind: Service
# metadata:
#   name: alertmanager
#   namespace: monitoring
# spec:
#   selector:
#     app: alertmanager
#   ports:
#   - port: 9093
#     targetPort: 9093
#   type: ClusterIP
