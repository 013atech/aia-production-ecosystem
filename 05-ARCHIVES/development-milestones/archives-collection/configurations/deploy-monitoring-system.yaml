# TEMPORARILY DISABLED FOR QUOTA COMPLIANCE
# This deployment has been temporarily disabled to meet GCP quota requirements
# Original content below (commented out):
#
# ---
# # Comprehensive Monitoring System
# # Prometheus, Grafana, and AlertManager for AIA Production
# 
# apiVersion: v1
# kind: Namespace
# metadata:
#   name: aia-monitoring
#   labels:
#     app.kubernetes.io/name: monitoring
# 
# ---
# # Prometheus ConfigMap
# apiVersion: v1
# kind: ConfigMap
# metadata:
#   name: prometheus-config
#   namespace: aia-monitoring
# data:
#   prometheus.yml: |
#     global:
#       scrape_interval: 15s
#       evaluation_interval: 15s
# 
#     rule_files:
#       - "/etc/prometheus/rules/*.yml"
# 
#     alerting:
#       alertmanagers:
#         - static_configs:
#             - targets:
#               - alertmanager:9093
# 
#     scrape_configs:
#       - job_name: 'prometheus'
#         static_configs:
#           - targets: ['localhost:9090']
# 
#       - job_name: 'aia-backend'
#         static_configs:
#           - targets: ['aia-backend-service-simple.aia-production.svc.cluster.local:8000']
#         metrics_path: '/metrics'
#         scrape_interval: 10s
# 
#       - job_name: 'aia-frontend'
#         static_configs:
#           - targets: ['aia-frontend-service.aia-production.svc.cluster.local:80']
#         scrape_interval: 30s
# 
#       - job_name: 'postgres'
#         static_configs:
#           - targets: ['aia-postgres.aia-production.svc.cluster.local:5432']
# 
#       - job_name: 'redis'
#         static_configs:
#           - targets: ['aia-redis.aia-production.svc.cluster.local:6379']
# 
#       - job_name: 'kubernetes-apiservers'
#         kubernetes_sd_configs:
#         - role: endpoints
#         scheme: https
#         tls_config:
#           ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
#         bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
#         relabel_configs:
#         - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
#           action: keep
#           regex: default;kubernetes;https
# 
#       - job_name: 'kubernetes-nodes'
#         kubernetes_sd_configs:
#         - role: node
#         scheme: https
#         tls_config:
#           ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
#         bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
#         relabel_configs:
#         - action: labelmap
#           regex: __meta_kubernetes_node_label_(.+)
#         - target_label: __address__
#           replacement: kubernetes.default.svc:443
#         - source_labels: [__meta_kubernetes_node_name]
#           regex: (.+)
#           target_label: __metrics_path__
#           replacement: /api/v1/nodes/${1}/proxy/metrics
# 
#   alerting_rules.yml: |
#     groups:
#     - name: aia_alerts
#       rules:
#       - alert: AIABackendDown
#         expr: up{job="aia-backend"} == 0
#         for: 1m
#         labels:
#           severity: critical
#         annotations:
#           summary: "AIA Backend is down"
#           description: "AIA Backend has been down for more than 1 minute."
# 
#       - alert: AIAHighResponseTime
#         expr: aia_request_duration_seconds > 2
#         for: 2m
#         labels:
#           severity: warning
#         annotations:
#           summary: "High response time detected"
#           description: "Response time is above 2 seconds."
# 
#       - alert: AIAHighMemoryUsage
#         expr: container_memory_usage_bytes{pod=~"aia-.*"} / container_spec_memory_limit_bytes > 0.8
#         for: 3m
#         labels:
#           severity: warning
#         annotations:
#           summary: "High memory usage detected"
#           description: "Memory usage is above 80%."
# 
# ---
# # Prometheus Deployment
# apiVersion: apps/v1
# kind: Deployment
# metadata:
#   name: prometheus
#   namespace: aia-monitoring
#   labels:
#     app: prometheus
# spec:
#   replicas: 1
#   selector:
#     matchLabels:
#       app: prometheus
#   template:
#     metadata:
#       labels:
#         app: prometheus
#     spec:
#       serviceAccountName: prometheus
#       containers:
#       - name: prometheus
#         image: prom/prometheus:v2.48.0
#         args:
#           - '--config.file=/etc/prometheus/prometheus.yml'
#           - '--storage.tsdb.path=/prometheus/'
#           - '--web.console.libraries=/etc/prometheus/console_libraries'
#           - '--web.console.templates=/etc/prometheus/consoles'
#           - '--storage.tsdb.retention.time=15d'
#           - '--web.enable-lifecycle'
#           - '--web.enable-admin-api'
#         ports:
#         - containerPort: 9090
#         resources:
#           requests:
#             memory: "128Mi"
#             cpu: "100m"
#           limits:
#             memory: "128Mi"
#             cpu: "100m"
#         volumeMounts:
#         - name: prometheus-config-volume
#           mountPath: /etc/prometheus/
#         - name: prometheus-storage-volume
#           mountPath: /prometheus/
#       volumes:
#       - name: prometheus-config-volume
#         configMap:
#           name: prometheus-config
#       - name: prometheus-storage-volume
#         emptyDir: {}
# 
# ---
# # Grafana Deployment
# apiVersion: apps/v1
# kind: Deployment
# metadata:
#   name: grafana
#   namespace: aia-monitoring
#   labels:
#     app: grafana
# spec:
#   replicas: 1
#   selector:
#     matchLabels:
#       app: grafana
#   template:
#     metadata:
#       labels:
#         app: grafana
#     spec:
#       containers:
#       - name: grafana
#         image: grafana/grafana:10.2.0
#         env:
#         - name: GF_SECURITY_ADMIN_PASSWORD
#           value: "aia-production-2025"
#         - name: GF_INSTALL_PLUGINS
#           value: "grafana-kubernetes-app,grafana-piechart-panel,grafana-worldmap-panel"
#         ports:
#         - containerPort: 3000
#         resources:
#           requests:
#             memory: "128Mi"
#             cpu: "100m"
#           limits:
#             memory: "128Mi"
#             cpu: "100m"
#         volumeMounts:
#         - name: grafana-storage
#           mountPath: /var/lib/grafana
#       volumes:
#       - name: grafana-storage
#         emptyDir: {}
# 
# ---
# # Performance Monitor Application
# apiVersion: apps/v1
# kind: Deployment
# metadata:
#   name: aia-performance-monitor
#   namespace: aia-production
#   labels:
#     app: aia-performance-monitor
# spec:
#   replicas: 1
#   selector:
#     matchLabels:
#       app: aia-performance-monitor
#   template:
#     metadata:
#       labels:
#         app: aia-performance-monitor
#     spec:
#       containers:
#       - name: performance-monitor
#         image: python:3.12-slim
#         env:
#         - name: PYTHONUNBUFFERED
#           value: "1"
#         envFrom:
#         - configMapRef:
#             name: aia-backend-config
#         - secretRef:
#             name: aia-secrets
#         command:
#         - /bin/bash
#         - -c
#         - |
#           set -e
#           echo "=== AIA Performance Monitor Starting ==="
# 
#           pip install --no-cache-dir requests psycopg2-binary redis schedule
# 
#           cat > /app/monitor.py << 'EOF'
#           import os
#           import time
#           import json
#           import logging
#           import requests
#           import schedule
#           import psycopg2
#           import redis
#           from datetime import datetime, timedelta
#           from threading import Thread
#           import subprocess
# 
#           logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
#           logger = logging.getLogger(__name__)
# 
#           class AIAPerformanceMonitor:
#               def __init__(self):
#                   self.backend_url = "http://aia-backend-service-simple:8000"
#                   self.frontend_url = "http://aia-frontend-service:80"
#                   self.redis_client = None
#                   self.db_conn = None
#                   self.metrics = {
#                       "system_health": 0.0,
#                       "response_times": [],
#                       "error_count": 0,
#                       "uptime": 0,
#                       "resource_usage": {}
#                   }
# 
#               def setup_connections(self):
#                   try:
#                       self.redis_client = redis.from_url(os.environ.get("REDIS_URL"), decode_responses=True)
#                       self.db_conn = psycopg2.connect(os.environ.get("DATABASE_URL"))
#                       logger.info("Monitoring connections established")
#                   except Exception as e:
#                       logger.error(f"Connection setup failed: {e}")
# 
#               def health_check(self):
#                   try:
#                       start_time = time.time()
#                       response = requests.get(f"{self.backend_url}/health", timeout=10)
#                       response_time = time.time() - start_time
# 
#                       if response.status_code == 200:
#                           data = response.json()
#                           self.metrics["response_times"].append(response_time)
#                           self.metrics["system_health"] = 1.0 if data.get("status") == "healthy" else 0.5
# 
#                           # Keep only last 100 response times
#                           if len(self.metrics["response_times"]) > 100:
#                               self.metrics["response_times"] = self.metrics["response_times"][-100:]
# 
#                           logger.info(f"Health check passed - Response time: {response_time:.3f}s")
#                           return True
#                       else:
#                           self.metrics["error_count"] += 1
#                           logger.warning(f"Health check failed - Status: {response.status_code}")
#                           return False
# 
#                   except Exception as e:
#                       self.metrics["error_count"] += 1
#                       self.metrics["system_health"] = 0.0
#                       logger.error(f"Health check exception: {e}")
#                       return False
# 
#               def api_endpoint_tests(self):
#                   endpoints = [
#                       "/api/v1/analytics/dashboard",
#                       "/api/v1/economy/status",
#                       "/api/v1/crypto/status",
#                       "/api/v1/dkg/status"
#                   ]
# 
#                   results = {}
#                   for endpoint in endpoints:
#                       try:
#                           start_time = time.time()
#                           response = requests.get(f"{self.backend_url}{endpoint}", timeout=5)
#                           response_time = time.time() - start_time
# 
#                           results[endpoint] = {
#                               "status": response.status_code,
#                               "response_time": response_time,
#                               "success": response.status_code == 200
#                           }
# 
#                           if response.status_code == 200:
#                               logger.info(f"✅ {endpoint} - {response_time:.3f}s")
#                           else:
#                               logger.warning(f"❌ {endpoint} - Status {response.status_code}")
# 
#                       except Exception as e:
#                           results[endpoint] = {"success": False, "error": str(e)}
#                           logger.error(f"❌ {endpoint} - Error: {e}")
# 
#                   return results
# 
#               def database_health_check(self):
#                   try:
#                       if self.db_conn:
#                           with self.db_conn.cursor() as cur:
#                               cur.execute("SELECT COUNT(*) FROM pg_stat_activity WHERE state = 'active'")
#                               active_connections = cur.fetchone()[0]
# 
#                               cur.execute("SELECT pg_database_size(current_database())")
#                               db_size = cur.fetchone()[0]
# 
#                               self.metrics["resource_usage"]["db_connections"] = active_connections
#                               self.metrics["resource_usage"]["db_size_mb"] = db_size / (1024 * 1024)
# 
#                               logger.info(f"Database: {active_connections} active connections, {db_size/(1024*1024):.1f}MB")
#                               return True
#                   except Exception as e:
#                       logger.error(f"Database health check failed: {e}")
#                       return False
# 
#               def redis_health_check(self):
#                   try:
#                       if self.redis_client:
#                           info = self.redis_client.info()
#                           self.metrics["resource_usage"]["redis_memory"] = info.get("used_memory", 0)
#                           self.metrics["resource_usage"]["redis_connections"] = info.get("connected_clients", 0)
# 
#                           logger.info(f"Redis: {info.get('connected_clients', 0)} clients, {info.get('used_memory_human', 'unknown')} memory")
#                           return True
#                   except Exception as e:
#                       logger.error(f"Redis health check failed: {e}")
#                       return False
# 
#               def resource_utilization_check(self):
#                   try:
#                       # Get pod resource usage
#                       result = subprocess.run(['kubectl', 'top', 'pods', '-n', 'aia-production', '--no-headers'],
#                                             capture_output=True, text=True)
# 
#                       if result.returncode == 0:
#                           lines = result.stdout.strip().split('\n')
#                           total_cpu = 0
#                           total_memory = 0
# 
#                           for line in lines:
#                               if 'aia-' in line:
#                                   parts = line.split()
#                                   if len(parts) >= 3:
#                                       cpu = parts[1].replace('m', '')
#                                       memory = parts[2].replace('Mi', '')
#                                       try:
#                                           total_cpu += int(cpu)
#                                           total_memory += int(memory)
#                                       except ValueError:
#                                           pass
# 
#                           self.metrics["resource_usage"]["total_cpu_millicores"] = total_cpu
#                           self.metrics["resource_usage"]["total_memory_mb"] = total_memory
# 
#                           logger.info(f"Resources: {total_cpu}m CPU, {total_memory}Mi Memory")
# 
#                   except Exception as e:
#                       logger.error(f"Resource check failed: {e}")
# 
#               def performance_test_suite(self):
#                   logger.info("🚀 Running comprehensive performance test suite")
# 
#                   # Basic health checks
#                   health_ok = self.health_check()
#                   db_ok = self.database_health_check()
#                   redis_ok = self.redis_health_check()
# 
#                   # API endpoint testing
#                   api_results = self.api_endpoint_tests()
# 
#                   # Resource utilization
#                   self.resource_utilization_check()
# 
#                   # Calculate overall system score
#                   passed_tests = sum([health_ok, db_ok, redis_ok])
#                   api_passed = sum(1 for r in api_results.values() if r.get("success"))
# 
#                   total_tests = 3 + len(api_results)
#                   overall_score = (passed_tests + api_passed) / total_tests
# 
#                   # Update metrics
#                   self.metrics["system_health"] = overall_score
#                   self.metrics["uptime"] = time.time()
# 
#                   # Store results in Redis for dashboard
#                   try:
#                       if self.redis_client:
#                           test_results = {
#                               "timestamp": datetime.utcnow().isoformat(),
#                               "overall_score": overall_score,
#                               "health_check": health_ok,
#                               "database_check": db_ok,
#                               "redis_check": redis_ok,
#                               "api_results": api_results,
#                               "metrics": self.metrics
#                           }
#                           self.redis_client.setex("aia:performance:latest", 3600, json.dumps(test_results))
#                           logger.info(f"📊 Performance test completed - Score: {overall_score:.2%}")
# 
#                   except Exception as e:
#                       logger.error(f"Failed to store results: {e}")
# 
#                   return overall_score
# 
#               def orchestration_load_test(self):
#                   logger.info("🎯 Running orchestration load test")
# 
#                   test_requests = [
#                       {"ta[STRIPE_KEY_PLACEHOLDER]": "research", "parameters": {"query": "AI trends"}},
#                       {"ta[STRIPE_KEY_PLACEHOLDER]": "analysis", "parameters": {"data": "sample"}},
#                       {"ta[STRIPE_KEY_PLACEHOLDER]": "synthesis", "parameters": {"sources": ["tech", "business"]}},
#                       {"ta[STRIPE_KEY_PLACEHOLDER]": "comprehensive", "parameters": {"scope": "full"}}
#                   ]
# 
#                   results = []
#                   for i, request in enumerate(test_requests):
#                       try:
#                           start_time = time.time()
#                           response = requests.post(f"{self.backend_url}/api/v1/agents/orchestrate",
#                                                  json=request, timeout=10)
#                           response_time = time.time() - start_time
# 
#                           if response.status_code == 200:
#                               data = response.json()
#                               results.append({
#                                   "request_id": i,
#                                   "ta[STRIPE_KEY_PLACEHOLDER]": request["ta[STRIPE_KEY_PLACEHOLDER]"],
#                                   "response_time": response_time,
#                                   "orchestration_id": data.get("orchestration_id"),
#                                   "agents": data.get("agents_activated"),
#                                   "status": "success"
#                               })
#                               logger.info(f"✅ Orchestration {i+1}/4 - {request['ta[STRIPE_KEY_PLACEHOLDER]']} - {response_time:.3f}s")
#                           else:
#                               logger.warning(f"❌ Orchestration {i+1} failed - Status {response.status_code}")
# 
#                       except Exception as e:
#                           logger.error(f"❌ Orchestration {i+1} error: {e}")
# 
#                   avg_response_time = sum(r.get("response_time", 0) for r in results) / len(results) if results else 0
#                   success_rate = len([r for r in results if r.get("status") == "success"]) / len(test_requests)
# 
#                   logger.info(f"🎯 Load test completed - Success rate: {success_rate:.2%}, Avg time: {avg_response_time:.3f}s")
# 
#                   return {"success_rate": success_rate, "avg_response_time": avg_response_time, "results": results}
# 
#               def continuous_monitoring(self):
#                   logger.info("🔄 Starting continuous monitoring")
# 
#                   # Schedule monitoring tasks
#                   schedule.every(30).seconds.do(self.health_check)
#                   schedule.every(2).minutes.do(self.performance_test_suite)
#                   schedule.every(10).minutes.do(self.orchestration_load_test)
# 
#                   while True:
#                       schedule.run_pending()
#                       time.sleep(10)
# 
#               def run(self):
#                   logger.info("🚀 AIA Performance Monitor v4.0.2 Starting")
# 
#                   self.setup_connections()
# 
#                   # Initial comprehensive test
#                   score = self.performance_test_suite()
#                   logger.info(f"🎯 Initial system score: {score:.2%}")
# 
#                   # Start continuous monitoring in background
#                   monitor_thread = Thread(target=self.continuous_monitoring)
#                   monitor_thread.daemon = True
#                   monitor_thread.start()
# 
#                   # Keep main thread alive
#                   try:
#                       while True:
#                           time.sleep(60)
#                           logger.info("🔄 Monitor heartbeat - System operational")
#                   except KeyboardInterrupt:
#                       logger.info("🛑 Monitor shutdown requested")
# 
#           if __name__ == "__main__":
#               monitor = AIAPerformanceMonitor()
#               monitor.run()
#           EOF
# 
#           mkdir -p /app
#           cd /app && python monitor.py
#         resources:
#           requests:
#             memory: "128Mi"
#             cpu: "100m"
#           limits:
#             memory: "128Mi"
#             cpu: "100m"
# 
# ---
# # Services
# apiVersion: v1
# kind: Service
# metadata:
#   name: prometheus
#   namespace: aia-monitoring
# spec:
#   selector:
#     app: prometheus
#   ports:
#   - port: 9090
#     targetPort: 9090
#   type: ClusterIP
# 
# ---
# apiVersion: v1
# kind: Service
# metadata:
#   name: grafana
#   namespace: aia-monitoring
# spec:
#   selector:
#     app: grafana
#   ports:
#   - port: 3000
#     targetPort: 3000
#   type: ClusterIP
# 
# ---
# # ServiceAccount for Prometheus
# apiVersion: v1
# kind: ServiceAccount
# metadata:
#   name: prometheus
#   namespace: aia-monitoring
# 
# ---
# # ClusterRole for Prometheus
# apiVersion: rbac.authorization.k8s.io/v1
# kind: ClusterRole
# metadata:
#   name: prometheus
# rules:
# - apiGroups: [""]
#   resources:
#   - nodes
#   - nodes/proxy
#   - services
#   - endpoints
#   - pods
#   verbs: ["get", "list", "watch"]
# - apiGroups:
#   - extensions
#   resources:
#   - ingresses
#   verbs: ["get", "list", "watch"]
# - nonResourceURLs: ["/metrics"]
#   verbs: ["get"]
# 
# ---
# # ClusterRoleBinding for Prometheus
# apiVersion: rbac.authorization.k8s.io/v1
# kind: ClusterRoleBinding
# metadata:
#   name: prometheus
# roleRef:
#   apiGroup: rbac.authorization.k8s.io
#   kind: ClusterRole
#   name: prometheus
# subjects:
# - kind: ServiceAccount
#   name: prometheus
#   namespace: aia-monitoring
